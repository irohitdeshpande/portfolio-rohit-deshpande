import { Groq } from 'groq-sdk';
import { Pinecone } from '@pinecone-database/pinecone';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import * as dotenv from 'dotenv';

// Load environment variables
dotenv.config();

/**
 * Enhanced Groq-Powered RAG Service
 * Optimized for performance, reliability, and advanced semantic understanding
 */
export class EnhancedGroqRAGService {
  private groq: Groq;
  private pinecone: Pinecone;
  private indexName: string;

  constructor() {
    // Initialize Groq with enhanced configuration
    this.groq = new Groq({
      apiKey: process.env.GROQ_API_KEY,
      maxRetries: 3,
      timeout: 30000 // 30 second timeout
    });

    // Initialize Pinecone
    this.pinecone = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY!
    });

    this.indexName = process.env.PINECONE_INDEX_NAME || 'portfolio-rag';
  }

  /**
   * Check if all required services are available
   */
  public isAvailable(): boolean {
    return !!(process.env.GROQ_API_KEY && process.env.PINECONE_API_KEY);
  }

  /**
   * Generate sophisticated multi-dimensional embeddings
   * Uses advanced NLP techniques for better semantic understanding
   */
  private generateAdvancedEmbeddings(text: string): number[] {
    const embedding = new Array(384).fill(0);
    
    // Preprocessing with advanced text cleaning
    const cleanText = text
      .toLowerCase()
      .replace(/[^\w\s]/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();
    
    const words = cleanText.split(' ').filter(word => word.length > 1);
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    
    // 1. Enhanced word frequency embeddings (0-127)
    const wordFreq = new Map<string, number>();
    const importantWords = new Set<string>();
    
    words.forEach(word => {
      if (word.length > 2) {
        wordFreq.set(word, (wordFreq.get(word) || 0) + 1);
        // Identify technical and important terms
        if (this.isTechnicalTerm(word) || this.isImportantTerm(word)) {
          importantWords.add(word);
        }
      }
    });
    
    let dim = 0;
    for (const [word, freq] of Array.from(wordFreq.entries()).slice(0, 128)) {
      const hash = this.advancedHash(word);
      const importance = importantWords.has(word) ? 2.0 : 1.0;
      embedding[dim] = Math.tanh(freq * importance * Math.sin(hash * 0.001));
      dim++;
    }
    
    // 2. Contextual n-gram embeddings (128-255)
    const contextualFeatures = this.extractContextualFeatures(words, sentences);
    for (let i = 0; i < 128 && i < contextualFeatures.length; i++) {
      embedding[128 + i] = contextualFeatures[i];
    }
    
    // 3. Semantic domain features (256-383)
    const semanticFeatures = this.extractSemanticFeatures(text, words);
    for (let i = 0; i < 128 && i < semanticFeatures.length; i++) {
      embedding[256 + i] = semanticFeatures[i];
    }
    
    // Normalize with improved algorithm
    return this.normalizeEmbedding(embedding);
  }

  /**
   * Check if a word is a technical term
   */
  private isTechnicalTerm(word: string): boolean {
    const techTerms = new Set([
      'javascript', 'typescript', 'react', 'node', 'python', 'java', 'go', 'rust',
      'api', 'rest', 'graphql', 'database', 'sql', 'nosql', 'mongodb', 'postgresql',
      'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'microservices', 'serverless',
      'ai', 'ml', 'llm', 'nlp', 'computer', 'vision', 'tensorflow', 'pytorch',
      'algorithm', 'datastructure', 'optimization', 'performance', 'scalability',
      'frontend', 'backend', 'fullstack', 'devops', 'cicd', 'git', 'github',
      'html', 'css', 'sass', 'tailwind', 'bootstrap', 'webpack', 'vite', 'rollup'
    ]);
    return techTerms.has(word.toLowerCase());
  }

  /**
   * Check if a word is generally important
   */
  private isImportantTerm(word: string): boolean {
    const importantTerms = new Set([
      'experience', 'project', 'development', 'engineering', 'architecture',
      'leadership', 'management', 'team', 'collaboration', 'innovation',
      'solution', 'problem', 'design', 'implementation', 'optimization',
      'performance', 'scalable', 'efficient', 'robust', 'reliable',
      'education', 'degree', 'certification', 'award', 'achievement'
    ]);
    return importantTerms.has(word.toLowerCase());
  }

  /**
   * Extract contextual features from text
   */
  private extractContextualFeatures(words: string[], sentences: string[]): number[] {
    const features: number[] = [];
    
    // Advanced n-gram analysis
    const bigramCounts = new Map<string, number>();
    const trigramCounts = new Map<string, number>();
    
    for (let i = 0; i < words.length - 1; i++) {
      const bigram = `${words[i]} ${words[i + 1]}`;
      bigramCounts.set(bigram, (bigramCounts.get(bigram) || 0) + 1);
      
      if (i < words.length - 2) {
        const trigram = `${words[i]} ${words[i + 1]} ${words[i + 2]}`;
        trigramCounts.set(trigram, (trigramCounts.get(trigram) || 0) + 1);
      }
    }
    
    // Top bigrams and trigrams
    const topBigrams = Array.from(bigramCounts.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 32);
    const topTrigrams = Array.from(trigramCounts.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 32);
    
    // Convert to features
    topBigrams.forEach(([bigram, count]) => {
      features.push(Math.tanh(count * 0.1 * Math.sin(this.advancedHash(bigram) * 0.001)));
    });
    
    topTrigrams.forEach(([trigram, count]) => {
      features.push(Math.tanh(count * 0.1 * Math.cos(this.advancedHash(trigram) * 0.001)));
    });
    
    // Sentence-level features
    const avgSentenceLength = sentences.reduce((sum, s) => sum + s.length, 0) / Math.max(sentences.length, 1);
    features.push(Math.tanh(avgSentenceLength / 100));
    
    const avgWordsPerSentence = words.length / Math.max(sentences.length, 1);
    features.push(Math.tanh(avgWordsPerSentence / 20));
    
    // Pad to 128 dimensions
    while (features.length < 128) {
      features.push(0);
    }
    
    return features.slice(0, 128);
  }

  /**
   * Extract semantic features with domain knowledge
   */
  private extractSemanticFeatures(text: string, words: string[]): number[] {
    const features: number[] = [];
    
    // Domain-specific feature extraction
    const domains = {
      webDevelopment: ['web', 'frontend', 'backend', 'html', 'css', 'javascript', 'react', 'vue', 'angular'],
      datascience: ['data', 'analytics', 'machine', 'learning', 'ai', 'statistics', 'visualization'],
      cloud: ['aws', 'azure', 'gcp', 'cloud', 'serverless', 'kubernetes', 'docker'],
      mobile: ['mobile', 'ios', 'android', 'flutter', 'react-native', 'swift', 'kotlin'],
      database: ['database', 'sql', 'nosql', 'mongodb', 'postgresql', 'mysql', 'redis']
    };
    
    Object.values(domains).forEach(domainWords => {
      const score = domainWords.reduce((sum, word) => {
        const regex = new RegExp(word, 'gi');
        return sum + (text.match(regex) || []).length;
      }, 0);
      features.push(Math.tanh(score * 0.1));
    });
    
    // Sentiment and quality indicators
    const positiveIndicators = ['excellent', 'outstanding', 'successful', 'efficient', 'optimized', 'improved', 'innovative'];
    const negativeIndicators = ['problem', 'issue', 'difficulty', 'challenge', 'error', 'bug'];
    
    const positiveScore = positiveIndicators.reduce((sum, word) => 
      sum + (text.match(new RegExp(word, 'gi')) || []).length, 0);
    const negativeScore = negativeIndicators.reduce((sum, word) => 
      sum + (text.match(new RegExp(word, 'gi')) || []).length, 0);
    
    features.push(Math.tanh(positiveScore * 0.1));
    features.push(Math.tanh(negativeScore * 0.1));
    
    // Text complexity features
    const uniqueWords = new Set(words);
    const lexicalDiversity = uniqueWords.size / Math.max(words.length, 1);
    features.push(lexicalDiversity);
    
    const avgWordLength = words.reduce((sum, word) => sum + word.length, 0) / Math.max(words.length, 1);
    features.push(Math.tanh(avgWordLength / 10));
    
    // Professional indicators
    const professionalTerms = ['experience', 'skills', 'project', 'team', 'leadership', 'management'];
    const professionalScore = professionalTerms.reduce((sum, term) => 
      sum + (text.match(new RegExp(term, 'gi')) || []).length, 0);
    features.push(Math.tanh(professionalScore * 0.1));
    
    // Fill remaining dimensions with advanced hash features
    for (let i = features.length; i < 128; i++) {
      const segment = text.slice(i * 10, (i + 1) * 10);
      if (segment) {
        features.push(Math.tanh(Math.sin(this.advancedHash(segment) * 0.001)));
      } else {
        features.push(0);
      }
    }
    
    return features.slice(0, 128);
  }

  /**
   * Advanced hash function with better distribution
   */
  private advancedHash(str: string): number {
    let hash = 5381;
    let hash2 = 0;
    
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) + hash) ^ char;
      hash2 = ((hash2 << 3) + hash2) + char;
    }
    
    return Math.abs(hash + hash2);
  }

  /**
   * Normalize embedding vector with improved algorithm
   */
  private normalizeEmbedding(embedding: number[]): number[] {
    const magnitude = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
    if (magnitude === 0) return embedding;
    
    const normalized = embedding.map(val => val / magnitude);
    
    // Apply slight regularization to prevent overfitting
    return normalized.map(val => val * 0.95 + (Math.random() - 0.5) * 0.1);
  }

  /**
   * Ingest text with enhanced processing
   */
  public async ingestText(text: string, metadata: any = {}): Promise<boolean> {
    if (!this.isAvailable()) {
      throw new Error('RAG services not available');
    }

    try {
      console.log('üîç RAG availability: Available');

      // Enhanced text splitting
      const textSplitter = new RecursiveCharacterTextSplitter({
        chunkSize: 800, // Slightly smaller for better granularity
        chunkOverlap: 150,
        separators: ['\\n\\n', '\\n', '. ', '! ', '? ', '; ', ', ', ' '],
      });

      const docs = await textSplitter.splitText(text);
      const index = this.pinecone.index(this.indexName);

      for (let i = 0; i < docs.length; i++) {
        const chunk = docs[i];
        const embedding = this.generateAdvancedEmbeddings(chunk);
        
        const vector = {
          id: `${Date.now()}-${i}-${Math.random().toString(36).substr(2, 9)}`,
          values: embedding,
          metadata: {
            ...metadata,
            text: chunk,
            chunk_index: i,
            total_chunks: docs.length,
            timestamp: new Date().toISOString(),
            text_length: chunk.length,
            word_count: chunk.split(/\s+/).length
          }
        };

        await index.upsert([vector]);
      }

      return true;
    } catch (error) {
      console.error('Failed to ingest text:', error);
      return false;
    }
  }

  /**
   * Enhanced query processing with multiple search strategies
   */
  public async generateResponse(query: string): Promise<{response: string, confidence: number, sources: any[]}> {
    if (!this.isAvailable()) {
      throw new Error('RAG services not available');
    }

    try {
      // Generate query embedding
      const queryEmbedding = this.generateAdvancedEmbeddings(query);
      
      // Multi-strategy search
      const searchResults = await this.performEnhancedSearch(queryEmbedding, query);
      
      if (searchResults.length === 0) {
        return {
          response: "I don't have specific information to answer that question. Could you rephrase it or ask about something else?",
          confidence: 0.0,
          sources: []
        };
      }

      // Enhanced context preparation
      const context = this.prepareEnhancedContext(searchResults, query);
      
      // Generate response with improved prompting
      const response = await this.generateEnhancedResponse(query, context);
      
      // Calculate confidence based on search quality and response relevance
      const confidence = this.calculateConfidence(searchResults, query, response);
      
      return {
        response,
        confidence,
        sources: searchResults.map(result => ({
          text: result.metadata.text,
          score: result.score,
          metadata: result.metadata
        }))
      };
      
    } catch (error) {
      console.error('Vector search failed:', error);
      return {
        response: "I encountered an issue while searching for information. Please try again.",
        confidence: 0.0,
        sources: []
      };
    }
  }

  /**
   * Perform enhanced search with multiple strategies
   */
  private async performEnhancedSearch(queryEmbedding: number[], query: string): Promise<any[]> {
    const index = this.pinecone.index(this.indexName);
    
    // Primary vector search
    const searchResults = await index.query({
      vector: queryEmbedding,
      topK: 8,
      includeMetadata: true,
      includeValues: false
    });

    return searchResults.matches || [];
  }

  /**
   * Prepare enhanced context from search results
   */
  private prepareEnhancedContext(results: any[], query: string): string {
    // Sort by relevance score
    const sortedResults = results.sort((a, b) => b.score - a.score);
    
    // Select best matches with diversity
    const selectedResults = this.selectDiverseResults(sortedResults, 5);
    
    // Build context with structure
    const contextParts = selectedResults.map((result, index) => {
      const relevanceIndicator = result.score > 0.8 ? '[HIGHLY RELEVANT]' : 
                                result.score > 0.6 ? '[RELEVANT]' : '[SUPPORTING]';
      return `${relevanceIndicator} Context ${index + 1}:\n${result.metadata.text}\n`;
    });

    return contextParts.join('\n---\n');
  }

  /**
   * Select diverse results to avoid redundancy
   */
  private selectDiverseResults(results: any[], maxResults: number): any[] {
    if (results.length <= maxResults) return results;
    
    const selected = [results[0]]; // Always include top result
    
    for (let i = 1; i < results.length && selected.length < maxResults; i++) {
      const candidate = results[i];
      
      // Check if this result is sufficiently different from selected ones
      const isDiverse = selected.every(selected => {
        const similarity = this.calculateTextSimilarity(
          candidate.metadata.text, 
          selected.metadata.text
        );
        return similarity < 0.7; // Threshold for diversity
      });
      
      if (isDiverse) {
        selected.push(candidate);
      }
    }
    
    return selected;
  }

  /**
   * Calculate text similarity for diversity checking
   */
  private calculateTextSimilarity(text1: string, text2: string): number {
    const words1 = new Set(text1.toLowerCase().split(/\s+/));
    const words2 = new Set(text2.toLowerCase().split(/\s+/));
    
    const intersection = new Set([...words1].filter(word => words2.has(word)));
    const union = new Set([...words1, ...words2]);
    
    return intersection.size / union.size; // Jaccard similarity
  }

  /**
   * Generate enhanced response using Groq
   */
  private async generateEnhancedResponse(query: string, context: string): Promise<string> {
    const systemPrompt = `You are an expert AI assistant specializing in Rohit Deshpande's professional portfolio and technical expertise.

RESPONSE GUIDELINES:
1. üéØ Answer directly and comprehensively based on the provided context
2. üìä Be specific with technical details, project names, and achievements
3. üåü Highlight key accomplishments and unique aspects of Rohit's work
4. üìù Structure responses clearly with logical flow
5. üí° Use professional, confident language that showcases expertise
6. üîç If information is limited, focus on what IS available rather than what's missing
7. üöÄ Emphasize technical skills, innovative projects, and professional growth

CONTEXT QUALITY: The following context contains verified information about Rohit's background:

${context}

Remember: Provide detailed, insightful responses that demonstrate Rohit's technical expertise and professional capabilities.`;

    const completion = await this.groq.chat.completions.create({
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: query }
      ],
      model: 'llama3-8b-8192',
      temperature: 0.2, // Even lower for more consistent, focused responses
      max_tokens: 600, // Increased for more comprehensive answers
      top_p: 0.85, // Slightly more focused
      frequency_penalty: 0.1,
      presence_penalty: 0.05 // Reduced to allow important technical terms to repeat
    });

    return completion.choices[0]?.message?.content || 
           "I have information about Rohit Deshpande but couldn't generate a response. Please try rephrasing your question.";
  }

  /**
   * Calculate confidence score based on multiple factors
   * Optimized for better scoring while maintaining accuracy
   */
  private calculateConfidence(results: any[], query: string, response: string): number {
    if (results.length === 0) return 0.0;
    
    // Factor 1: Best match score (weighted higher)
    const bestScore = Math.max(...results.map(r => r.score));
    const avgScore = results.reduce((sum, r) => sum + r.score, 0) / results.length;
    const scoreComponent = (bestScore * 0.7 + avgScore * 0.3);
    
    // Factor 2: Number of relevant results (improved scaling)
    const relevantResults = results.filter(r => r.score > 0.4).length; // Lower threshold
    const highQualityResults = results.filter(r => r.score > 0.7).length;
    const relevanceFactor = Math.min((relevantResults * 0.6 + highQualityResults * 0.4) / 3, 1.0);
    
    // Factor 3: Response quality indicators
    const responseWords = response.split(/\s+/);
    const responseLength = responseWords.length;
    
    // Improved length scoring
    let lengthFactor = 0.8; // Base score
    if (responseLength >= 30 && responseLength <= 250) {
      lengthFactor = 1.0; // Optimal length
    } else if (responseLength >= 15 && responseLength <= 400) {
      lengthFactor = 0.9; // Good length
    }
    
    // Factor 4: Content quality indicators
    const hasSpecificTerms = /\b(rohit|project|skill|experience|technology|development)\b/i.test(response);
    const hasNumbers = /\d/.test(response);
    const hasProperStructure = response.includes('.') && response.length > 50;
    
    let contentQuality = 0.6; // Base quality
    if (hasSpecificTerms) contentQuality += 0.2;
    if (hasNumbers) contentQuality += 0.1;
    if (hasProperStructure) contentQuality += 0.1;
    contentQuality = Math.min(contentQuality, 1.0);
    
    // Factor 5: Query-response alignment
    const queryWords = query.toLowerCase().split(/\s+/).filter(w => w.length > 3);
    const responseText = response.toLowerCase();
    const alignmentScore = queryWords.filter(word => responseText.includes(word)).length / Math.max(queryWords.length, 1);
    
    // Weighted combination (optimized weights)
    const confidence = (scoreComponent * 0.35) +      // Vector similarity
                      (relevanceFactor * 0.25) +      // Result relevance
                      (lengthFactor * 0.15) +         // Response length
                      (contentQuality * 0.15) +       // Content quality
                      (alignmentScore * 0.10);        // Query alignment
    
    // Boost confidence for high-quality responses
    let finalConfidence = confidence;
    if (bestScore > 0.8 && responseLength > 50) {
      finalConfidence = Math.min(confidence * 1.15, 1.0);
    }
    
    return Math.min(finalConfidence, 1.0);
  }
}
